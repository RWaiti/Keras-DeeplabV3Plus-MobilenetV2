{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Turn off GPU\n",
    "if False:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from utils.model_utils import lastLayerToArgMax\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "print(tf.__version__)\n",
    "print(gpus)\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024 * 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model-saved/deeplabV3+_mobileNetV2/NEW_5/LAST_MODEL\\\\layer_12\\\\alpha_0.5\\\\loss_iou_coef\\\\l1_0\\\\l2_0.01\\\\VERTICAL_FLIP_False.ckpt', 'model-saved/deeplabV3+_mobileNetV2/NEW_5/LAST_MODEL\\\\layer_12\\\\alpha_0.5\\\\loss_iou_coef\\\\l1_0\\\\l2_0.01\\\\VERTICAL_FLIP_True.ckpt'] 2\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# last_models = sorted(glob(\"model-saved/deeplabV3+_mobileNetV2/NEW_4/GRID_SEARCH/*/*/*/*/*/*.ckpt\"))\n",
    "last_models = sorted(glob(\"model-saved/deeplabV3+_mobileNetV2/NEW_5/LAST_MODEL/*/*/*/*/*/*.ckpt\"))\n",
    "\n",
    "modelPaths = last_models\n",
    "print(last_models, len(last_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize = (240, 320)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    }
   ],
   "source": [
    "modelPath = sorted(glob(\"model-saved/deeplabV3+_mobileNetV2/NEW_6/kfold/*/*/*/*/*/*.ckpt\"))[0]\n",
    "model = tf.keras.models.load_model(modelPath, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 2\n",
      "None\n",
      "12\n",
      "0.5\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "model-saved/deeplabV3+_mobileNetV2/NEW_5/LAST_MODEL\\layer_12\\alpha_0.5\\loss_iou_coef\\l1_0\\l2_0.01\\VERTICAL_FLIP_False.ckpt\n",
      "2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 46). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rafae\\AppData\\Local\\Temp\\tmp_294mrsq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rafae\\AppData\\Local\\Temp\\tmp_294mrsq\\assets\n",
      "d:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 of 2\n",
      "None\n",
      "12\n",
      "0.5\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-saved/deeplabV3+_mobileNetV2/NEW_5/LAST_MODEL\\layer_12\\alpha_0.5\\loss_iou_coef\\l1_0\\l2_0.01\\VERTICAL_FLIP_True.ckpt\n",
      "2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 46). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rafae\\AppData\\Local\\Temp\\tmp_2jfnebp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rafae\\AppData\\Local\\Temp\\tmp_2jfnebp\\assets\n",
      "d:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "from utils.model_utils import BatchGenerator\n",
    "from utils.model_utils import toTFlite\n",
    "from tensorflow import lite as tflite\n",
    "\n",
    "for i, modelPath in enumerate(modelPaths):\n",
    "    print(f\"{i+1} of {len(last_models)}\")\n",
    "    modelSplit = modelPath.replace(\"/\", \"\\\\\").split(\"\\\\\")\n",
    "\n",
    "    # TEST = modelSplit[4] == \"True\"\n",
    "    # deeplayer = modelSplit[5].replace(\"layer_\", \"\")\n",
    "    # alpha = float(modelSplit[6].replace(\"alpha_\", \"\"))\n",
    "\n",
    "    TEST = None\n",
    "    deeplayer = modelSplit[4].replace(\"layer_\", \"\")\n",
    "    alpha = float(modelSplit[5].replace(\"alpha_\", \"\"))\n",
    "\n",
    "    print(TEST)\n",
    "    print(deeplayer)\n",
    "    print(alpha)\n",
    "\n",
    "    mobileLayers = {\n",
    "        \"shallowLayer\": \"block_2_project_BN\",\n",
    "        \"deepLayer\": f\"block_{deeplayer}_project_BN\"}\n",
    "    \n",
    "    # if TEST is not None:\n",
    "    #     model = models.deeplabV3(\n",
    "    #         imageSize=imageSize, nClasses=n_classes, alpha=alpha, withArgmax=True, mobileLayers=mobileLayers, TEST=TEST)\n",
    "    # else:\n",
    "    #     model = models.deeplabV3Alpha(\n",
    "    #         imageSize=imageSize, nClasses=n_classes, alpha=alpha, last=0.25, withArgmax=True, mobileLayers=mobileLayers)\n",
    "    model = tf.keras.models.load_model(modelPath, compile=False)\n",
    "    model = lastLayerToArgMax(model=model)\n",
    "\n",
    "    print(modelPath)\n",
    "\n",
    "    images = glob(\"utils\\\\split_3\\\\TrainVal\\\\img\\\\*\")\n",
    "    print(len(images))\n",
    "\n",
    "    toTFlite(\n",
    "        model=model,\n",
    "        savePath=modelPath.replace(\".ckpt\", \"\"),\n",
    "        representativeDatasetGen=BatchGenerator(images),\n",
    "        supportedOps=[\n",
    "            tflite.OpsSet.SELECT_TF_OPS,\n",
    "            tflite.OpsSet.TFLITE_BUILTINS])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
