{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f67182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ, path\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from absl import logging as absl_logging\n",
    "absl_logging.set_verbosity(absl_logging.ERROR)\n",
    "\n",
    "if False: # if True: turn off GPU\n",
    "    environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    gpu = False\n",
    "else:\n",
    "    gpu = True\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "if gpu:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024 * 8))])\n",
    "        print(gpus)\n",
    "    except IndexError:\n",
    "        print(\"gpu not appearing\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9914fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "search_space = { \"lr\": [1e-3, 1e-4, 1e-5],\n",
    "                \"alpha\": [0.5, 0.75, 1.0],\n",
    "                \"deeplayer\": [6, 7, 8, 9, 10, 11],}\n",
    "\n",
    "search_space = {\n",
    "    \"l1\": [1e-3],\n",
    "    \"l2\": [1e-3, 1e-4, 1e-5],\n",
    "    \"lr\": [1e-3, 1e-5],\n",
    "    \"alpha\": [0.5, 1.0],\n",
    "    \"deeplayer\": [12],\n",
    "    \"epochs\": [500]}\n",
    "\n",
    "all_iter = 1 * 3 * 2 * 2 * 1 * 1\n",
    "n_iter = int(all_iter * 0.75)\n",
    "\n",
    "print(all_iter, n_iter)\n",
    "\n",
    "search_space = list(ParameterSampler(search_space, n_iter=n_iter, random_state=SEED))\n",
    "\n",
    "for _dict in search_space:\n",
    "    print(_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5774ef",
   "metadata": {},
   "source": [
    "##### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2193e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils import data_utils\n",
    "\n",
    "DATA_DIR = \"utils/split/_split_/_type_\"\n",
    "\n",
    "train_val_X = sorted(glob(DATA_DIR.replace(\"_split_\", \"TrainVal\").replace(\"_type_\", \"img\") + \"\\\\*\"))\n",
    "train_val_Y = sorted(glob(DATA_DIR.replace(\"_split_\", \"TrainVal\").replace(\"_type_\", \"mask\") + \"\\\\*\"))\n",
    "\n",
    "test_X = sorted(glob(DATA_DIR.replace(\"_split_\", \"Test\").replace(\"_type_\", \"img\") + \"\\\\*\"))\n",
    "test_Y = sorted(glob(DATA_DIR.replace(\"_split_\", \"Test\").replace(\"_type_\", \"mask\") + \"\\\\*\"))\n",
    "# test_data = data_utils.load_testset(test_X, test_Y, IMAGE_SIZE=IMG_SIZE, BATCH_SIZE=1, REMAP=\"binary\")\n",
    "\n",
    "\n",
    "len(train_val_X), len(train_val_Y), len(test_X), len(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc951be4",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import lossesAccuracyfuncs\n",
    "from utils import model_utils\n",
    "import models\n",
    "\n",
    "for _dict in search_space:\n",
    "    lr = _dict[\"lr\"]\n",
    "    alpha = _dict[\"alpha\"]\n",
    "    deeplayer = _dict[\"deeplayer\"]\n",
    "    l1, l2 = _dict[\"l1\"], _dict[\"l2\"]\n",
    "\n",
    "    mobileLayers = {\"shallowLayer\": \"block_2_project_BN\",\n",
    "                    \"deepLayer\": f\"block_{deeplayer}_project_BN\"}\n",
    "    \n",
    "    # Train image has 1/5 chance to be a fog image\n",
    "    # Train image has 1/3 chance to be flipped\n",
    "    train_val_folds = data_utils.load_dataset(\n",
    "        train_val_X, train_val_Y, IMAGE_SIZE=IMG_SIZE, BATCH_SIZE=BATCH_SIZE, REMAP=\"binary\",\n",
    "        N_FOLDS=5, SEED=SEED, use_fog=True, flip=True) \n",
    "    \n",
    "    for fold, (trainDataset, valDataset, n_classes) in enumerate(train_val_folds):\n",
    "        MODEL_NAME = \"deeplabV3+_mobileNetV2\"\n",
    "        SAVE_PATH = f\"model-saved\\\\{MODEL_NAME}\\\\deeplayer-{deeplayer}_alpha_{alpha}_lr_{lr}_regularizer_l1_{l1}_l2_{l2}\\\\{fold}\"\n",
    "\n",
    "        print(MODEL_NAME)\n",
    "        print(f\"lr: {lr} | alpha: {alpha} | deeplayer: {deeplayer} | fold: {fold} | l1: {l1} | l2: {l2}\")\n",
    "\n",
    "        model = models.deeplabV3(\n",
    "            imageSize=IMG_SIZE, nClasses=n_classes, alpha=alpha, mobileLayers=mobileLayers,\n",
    "            kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2))\n",
    "\n",
    "        losses = lossesAccuracyfuncs.Losses_n_Metrics()\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, ignore_class=n_classes),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.MeanIoU(num_classes=n_classes, ignore_class=n_classes),\n",
    "                losses.diceAccuracy, losses.jaccardDistance],\n",
    "            sample_weight_mode=\"temporal\")\n",
    "\n",
    "        history = model.fit(\n",
    "            x=trainDataset, validation_data=valDataset, batch_size=BATCH_SIZE, verbose=2,\n",
    "            epochs=_dict[\"epochs\"], callbacks=model_utils.callbacks_func(savePath=SAVE_PATH, monitor=\"val_loss\"))\n",
    "\n",
    "        with open(path.join(SAVE_PATH, \"metrics.json\"), mode='w') as f:\n",
    "            pd.DataFrame(history.history).to_json(f)\n",
    "\n",
    "        clear_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a50ac",
   "metadata": {},
   "source": [
    "##### TFLITE Converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# representativeData = representativeDatasetGen(path=\"../cityscapes/alldata\")\n",
    "# supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "23e7a0b0a1ade771721f510eeefb26c42b77578caec684a32e14f7e5228bf389"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
