{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f67182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "if False: # if True: turn off GPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    gpu = False\n",
    "else:\n",
    "    gpu = True\n",
    "\n",
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from utils.cityscapesSequence import CitySequence, labels\n",
    "import utils.dataUtils as dataUtils\n",
    "from modelclass import DeeplabV3\n",
    "\n",
    "if gpu:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024 * 8))])\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9914fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"..\", \"cityscapes\", \"allData\")\n",
    "\n",
    "batchSize = 8\n",
    "imageSize = 256\n",
    "lrs = [5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "alphas = [0.35, 0.50, 0.75, 1.0, 1.3, 1.4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5774ef",
   "metadata": {},
   "source": [
    "##### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9d2599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from: ..\\cityscapes\\allData\n",
      "Getting train data from: ..\\cityscapes\\allData\\leftImg8bit\\train\\*\\*_leftImg8bit.png\n",
      "Getting val data from: ..\\cityscapes\\allData\\leftImg8bit\\val\\*\\*_leftImg8bit.png\n",
      "Getting test data from: ..\\cityscapes\\allData\\leftImg8bit\\test\\*\\*_leftImg8bit.png\n",
      "TrainVal:  3475 Test:  1525\n"
     ]
    }
   ],
   "source": [
    "def getData(path=\"\", type=\"gtFine\", extra=False, nSplits=5, seed=0):\n",
    "    # Load data\n",
    "    xTrainVal, yTrainVal, xTest, yTest = dataUtils.getXY(path=path, extra=extra, type=type)\n",
    "    print(\"TrainVal: \", len(xTrainVal), \"Test: \", len(yTest))\n",
    "\n",
    "    # Split the data in train and validation folds\n",
    "    return dataUtils.splitTrainValFolds(xTrainVal, yTrainVal, nSplits=nSplits, seed=seed)\n",
    "\n",
    "\n",
    "def createDatasetObject(trainValFolds, imageSize=imageSize, batchSize=1, remap=\"binary\"):\n",
    "    for i, (xTrain, yTrain, xVal, yVal) in enumerate(trainValFolds):\n",
    "        print(\"Fold\", i, \"Train: \", len(xTrain), \"Val: \", len(xVal))\n",
    "\n",
    "        dataUtils.dataShuffle(xData=xTrain, yData=yTrain)\n",
    "\n",
    "        # Create the dataset\n",
    "        trainDataset = CitySequence(xTrain, yTrain, batchSize=batchSize, imageSize=imageSize, remap=remap, blur=0, crop=True, horizontalFlip=True, verticalFlip=True, brightness=0.1)\n",
    "        valDataset = CitySequence(xVal, yVal, batchSize=batchSize, imageSize=imageSize, remap=remap, blur=0, crop=True, horizontalFlip=False, verticalFlip=False, brightness=0)\n",
    "\n",
    "        yield trainDataset, valDataset, trainDataset.nClasses\n",
    "\n",
    "\n",
    "kf = getData(path=DATA_DIR, type=\"gtFine\", extra=False, nSplits=5, seed=13)\n",
    "data = createDatasetObject(kf, imageSize=imageSize, batchSize=batchSize, remap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc951be4",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e802cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Train:  2780 Val:  695\n",
      "Fold: 0 learning rate: 0.0005 alpha: 0.35\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "\n",
    "for deeplayer in [6, 7, 8, 9, 10, 11, 12]:\n",
    "    mobileLayers={\"shallowLayer\": \"block_2_project_BN\", \"deepLayer\": \"block_\" + str(deeplayer) + \"_project_BN\"}\n",
    "    \n",
    "    for lr in lrs:\n",
    "        for alpha in alphas:\n",
    "            for i, (trainDataset, valDataset, nClasses) in enumerate(data):\n",
    "                if alpha > 1. and deeplayer > 10:\n",
    "                    continue\n",
    "                \n",
    "                print(\"Fold:\", i, \"learning rate:\", lr, \"alpha:\", alpha)\n",
    "                \n",
    "                MODEL_NAME = \"deeplabv3plus_fold_\" + str(i) + \"_lr_\" + str(lr) + \"_alpha_\" + str(alpha) + \"_binary_\" + str(imageSize) + \"x\" + str(imageSize) + \"_deeplayer_\" + str(deeplayer)\n",
    "\n",
    "                model = DeeplabV3(imageSize=imageSize, nClasses=nClasses, alpha=alpha, modelName=MODEL_NAME, mobileLayers=mobileLayers)\n",
    "                \n",
    "                model.run(trainDataset, valDataset, epochs=1000, learningRate=lr, batchSize=batchSize, monitor=\"val_loss\", log=True)\n",
    "\n",
    "                # Evaluate the model\n",
    "                losses[MODEL_NAME] = model.evaluate(valDataset)\n",
    "                print(\"losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b318f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a50ac",
   "metadata": {},
   "source": [
    "##### TFLITE Converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imageUtils import representativeDatasetGen\n",
    "\n",
    "representativeData = representativeDatasetGen(path=\"../cityscapes/alldata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"binary_rain_fog.hdf5\"\n",
    "MODEL_PATH = os.path.join(\"model-saved\", MODEL_NAME)\n",
    "\n",
    "import models\n",
    "importlib.reload(models)\n",
    "\n",
    "image_size = 256\n",
    "num_classes = 2\n",
    "alpha = 1\n",
    "\n",
    "model = models.DeeplabV3(image_size, num_classes, alpha, modelName=MODEL_NAME)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "model.toTFlite(representative_dataset_gen=representativeData, supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS])\n",
    "\n",
    "MODEL_NAME = \"binary_rain_fog.hdf5\"\n",
    "MODEL_PATH = os.path.join(\"model-saved\", MODEL_NAME)\n",
    "\n",
    "model = models.DeeplabV3(image_size, num_classes, alpha, modelName=MODEL_NAME)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "model.toTFlite(representative_dataset_gen=representativeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"binary_rain_fog.hdf5\"\n",
    "MODEL_PATH = os.path.join(\"model-saved\", MODEL_NAME)\n",
    "\n",
    "import models\n",
    "importlib.reload(models)\n",
    "\n",
    "image_size = 256\n",
    "num_classes = 2\n",
    "alpha = 1\n",
    "\n",
    "model = models.DeeplabV3(image_size, num_classes, alpha, modelName=MODEL_NAME)\n",
    "\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd184ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "23e7a0b0a1ade771721f510eeefb26c42b77578caec684a32e14f7e5228bf389"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
